{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Before you dive into the implementations, I highly recommend first learning the heart of each algorithmâ€”its core idea and how it works. You can explore this through YouTube tutorials, books, or online courses. This repository is meant to complement that knowledge by showing how to translate concepts into working code.**\n",
        "# Model Evaluation\n",
        "\n",
        "This document provides an overview of essential techniques for evaluating machine learning models.\n",
        "\n",
        "## I. Hold-out Method (Train-Test Split)\n",
        "\n",
        "The hold-out method is the simplest approach to evaluate model performance. It involves dividing the dataset into two distinct subsets:\n",
        "\n",
        "*   **Training Set:** Used to train the machine learning model.\n",
        "*   **Test Set (Hold-out Set):** Held back and used to evaluate the trained model on unseen data.\n",
        "\n",
        "**Process:**\n",
        "\n",
        "1.  **Split:** Divide the dataset (e.g., 80% training, 20% testing).\n",
        "2.  **Train:** Train the model on the training set.\n",
        "3.  **Evaluate:** Use the trained model to make predictions on the test set.\n",
        "4.  **Calculate Metrics:** Calculate evaluation metrics (e.g., accuracy, RMSE).\n",
        "\n",
        "**Advantages:** Simple, computationally inexpensive, useful for large datasets.\n",
        "\n",
        "**Disadvantages:** Sensitive to data split, may not be suitable for small datasets.\n",
        "\n",
        "## II. Cross-Validation\n",
        "\n",
        "Cross-validation is a more robust technique than the hold-out method. It involves partitioning the dataset into multiple subsets (folds), training the model on some folds, and evaluating it on the remaining folds. This process is repeated multiple times, and the results are averaged.\n",
        "\n",
        "### Types of Cross-Validation\n",
        "\n",
        "1.  **k-fold Cross-Validation**\n",
        "\n",
        "    *   The dataset is divided into k equal-sized folds.\n",
        "    *   The model is trained k times, each time using a different fold as the test set and the remaining k-1 folds as the training set.\n",
        "    *   The performance is averaged across all k evaluations.\n",
        "    *   Common values for k are 5 and 10.\n",
        "\n",
        "    **Example (5-fold):**\n",
        "\n",
        "    Data: `[Fold 1] [Fold 2] [Fold 3] [Fold 4] [Fold 5]`\n",
        "\n",
        "    *   Round 1: Train on `[2, 3, 4, 5]`, Test on `[1]`\n",
        "    *   Round 2: Train on `[1, 3, 4, 5]`, Test on `[2]`\n",
        "    *   ...\n",
        "\n",
        "2.  **Stratified k-fold Cross-Validation**\n",
        "\n",
        "    *   Ensures that each fold has the same proportion of target classes as the original dataset.\n",
        "    *   Essential for imbalanced datasets.\n",
        "\n",
        "3.  **Leave-One-Out Cross-Validation (LOOCV)**\n",
        "\n",
        "    *   A special case of k-fold where k equals the number of data points.\n",
        "    *   Each data point is used as the test set once.\n",
        "    *   Computationally expensive for large datasets.\n",
        "\n",
        "4.  **Time Series Cross-Validation**\n",
        "\n",
        "    *   Designed for time series data where the order of data points is important.\n",
        "    *   Uses a rolling or expanding window approach to prevent data leakage.\n",
        "\n",
        "5.  **Nested Cross-Validation**\n",
        "\n",
        "    *   Used for both hyperparameter tuning and model evaluation.\n",
        "    *   Involves an outer loop for evaluation and an inner loop for hyperparameter tuning.\n",
        "    *   Provides a less biased estimate of model performance.\n",
        "\n",
        "### Cross-Validation vs. Hold-out Method (Train-Test Split)\n",
        "\n",
        "| Feature             | Hold-out Method                      | Cross-Validation                                        |\n",
        "|----------------------|--------------------------------------|--------------------------------------------------------|\n",
        "| Data Usage          | Single split into train and test sets | Multiple splits; each data point used for both training and testing |\n",
        "| Performance Estimate | Single evaluation on the test set     | Average performance across multiple evaluations        |\n",
        "| Reliability         | Can be sensitive to the specific split | More robust and reliable                               |\n",
        "| Computational Cost  | Lower                                  | Higher                                                   |\n",
        "\n",
        "### How Cross-Validation Helps\n",
        "\n",
        "*   **Reliable Performance Estimate:** Provides a more robust estimate of how well a model will perform on unseen data.\n",
        "*   **Effective Use of Data:** Especially useful for small datasets.\n",
        "*   **Model Selection:** Helps compare different models or hyperparameter settings.\n",
        "*   **Reduces Overfitting:** Gives a better indication of how well a model generalizes, preventing overfitting to a specific train/test split.\n",
        "\n",
        "### Hyperparameter Tuning with Cross-Validation\n",
        "\n",
        "*   **Define a Grid:** Specify a range of values for each hyperparameter.\n",
        "*   **Cross-Validation for Each Combination:** Perform k-fold cross-validation for each hyperparameter combination.\n",
        "*   **Select Best Hyperparameters:** Choose the combination with the best average performance.\n",
        "\n",
        "### Nested Cross-Validation (Detailed)\n",
        "\n",
        "*   **Outer Loop (Evaluation):** Split data into k folds.\n",
        "*   **Inner Loop (Hyperparameter Tuning - for each outer fold):**\n",
        "    *   Split the outer fold's training data into subsets.\n",
        "    *   Test different hyperparameter values using cross-validation on these subsets.\n",
        "    *   Select the best hyperparameters.\n",
        "*   **Evaluation:** Train a model with the selected hyperparameters on the entire training set of the outer fold and evaluate it on the hold-out test fold.\n",
        "*   **Final Performance:** Average results from each outer fold.\n",
        "\n",
        "### Choosing the Number of Folds (k)\n",
        "\n",
        "*   **Common values:** 5 or 10.\n",
        "*   **Small datasets:** Consider LOOCV or lower k (e.g., 3).\n",
        "*   **Large datasets:** Lower k to reduce computational cost.\n",
        "*   Balance computational cost and reliability.\n",
        "\n",
        "### Key Takeaway\n",
        "\n",
        "Cross-validation is a powerful technique for evaluating and comparing machine learning models. It provides a more reliable estimate of performance than a simple train-test split, especially when dealing with limited data or when accurate performance estimation is crucial. Nested cross-validation further enhances this by providing an unbiased evaluation after hyperparameter tuning."
      ],
      "metadata": {
        "id": "Sr2Un0T1OvGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, LeaveOneOut, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "BmMHPY7ZnIri"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate a synthetic dataset (for demonstration)\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
        "df['target'] = y\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "a9nwevhqnLt2",
        "outputId": "cd2ec98a-3206-42f6-b103-8fc4e4dfdb17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0     1.470848  -0.360450  -0.591602  -0.728228   0.941690   1.065964   \n",
              "1     4.513369  -2.227103  -1.140747   2.018263  -2.238358  -0.497370   \n",
              "2    -2.355643   2.218601  -1.603269   0.873394   0.401483   0.717264   \n",
              "3    -1.596198  -0.857427   1.772434  -0.639361   1.419409  -0.438525   \n",
              "4     2.840049  -2.489600  -0.844902  -1.594362  -4.688517   0.459637   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "995  -0.952534   0.238036   0.331327   0.120452   3.539113  -0.556466   \n",
              "996  -3.434088  -1.020016  -0.726931  -1.787934  -3.247447   1.439954   \n",
              "997  -0.015335   1.883507   3.221682   2.878762  -3.854459  -1.862864   \n",
              "998   1.285071   1.618508  -1.700678   1.051307  -2.025566  -0.375928   \n",
              "999  -1.276148   0.988126  -0.716932  -1.622595   4.793812   0.554143   \n",
              "\n",
              "     feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
              "0     0.017832  -0.596184   1.840712  -1.497093  ...   -0.603968    2.899256   \n",
              "1     0.714550   0.938883  -2.395169   0.159837  ...    1.461499    3.954171   \n",
              "2    -0.859399  -1.042190  -2.175965   0.980231  ...    0.544434   -2.466258   \n",
              "3     0.281949   2.345145   1.006230   0.389135  ...   -1.025051   -2.422975   \n",
              "4     0.913607  -1.143505   1.263937  -2.040928  ...    4.176424    1.341742   \n",
              "..         ...        ...        ...        ...  ...         ...         ...   \n",
              "995   0.517210   2.324479  -0.123064  -2.143993  ...   -2.233344   -1.424993   \n",
              "996   1.075627  -2.812310   2.527895  -6.569889  ...    2.058341   -2.655348   \n",
              "997  -0.534772  -6.446245   0.976906   0.268957  ...    0.306705    4.747956   \n",
              "998   0.261185   1.514845  -2.452698   0.811538  ...   -1.600277    3.054941   \n",
              "999  -0.614424   0.339260   2.159058   0.034622  ...   -1.054176   -0.714592   \n",
              "\n",
              "     feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
              "0      0.037567   -1.249523    0.257963    0.416628    1.408208   -1.838041   \n",
              "1      0.309054    0.538184   -7.157865   -4.532216   -0.081800   -9.325362   \n",
              "2     -0.470256    0.073018   -2.203531   -2.299263   -1.742761   -0.271579   \n",
              "3      1.579807   -0.300713    4.267120    2.893775    1.236697    6.034785   \n",
              "4      0.133565    1.743819    1.531188    2.269808    0.053489   -3.151109   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "995    0.443893   -2.239507    1.650853    2.296884    0.438294    1.705011   \n",
              "996    0.566760    3.414485    5.391528    0.744789   -3.919345   -5.365949   \n",
              "997   -0.484956    7.601766    1.039739   -0.107586   -0.789566    0.282480   \n",
              "998    0.791745    0.982096   -2.942005   -4.929617    1.660500   -2.192116   \n",
              "999    0.096377   -4.757388    0.702176    2.109922    1.396287    3.412685   \n",
              "\n",
              "     feature_19  target  \n",
              "0     -0.833142       1  \n",
              "1      0.574386       1  \n",
              "2     -0.359285       0  \n",
              "3     -0.045711       0  \n",
              "4      1.603702       0  \n",
              "..          ...     ...  \n",
              "995   -1.504149       0  \n",
              "996    0.725590       0  \n",
              "997    0.825853       0  \n",
              "998    0.906871       1  \n",
              "999    0.726871       1  \n",
              "\n",
              "[1000 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-201af9ae-610a-482d-861b-e0bfd48e71ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.470848</td>\n",
              "      <td>-0.360450</td>\n",
              "      <td>-0.591602</td>\n",
              "      <td>-0.728228</td>\n",
              "      <td>0.941690</td>\n",
              "      <td>1.065964</td>\n",
              "      <td>0.017832</td>\n",
              "      <td>-0.596184</td>\n",
              "      <td>1.840712</td>\n",
              "      <td>-1.497093</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.603968</td>\n",
              "      <td>2.899256</td>\n",
              "      <td>0.037567</td>\n",
              "      <td>-1.249523</td>\n",
              "      <td>0.257963</td>\n",
              "      <td>0.416628</td>\n",
              "      <td>1.408208</td>\n",
              "      <td>-1.838041</td>\n",
              "      <td>-0.833142</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.513369</td>\n",
              "      <td>-2.227103</td>\n",
              "      <td>-1.140747</td>\n",
              "      <td>2.018263</td>\n",
              "      <td>-2.238358</td>\n",
              "      <td>-0.497370</td>\n",
              "      <td>0.714550</td>\n",
              "      <td>0.938883</td>\n",
              "      <td>-2.395169</td>\n",
              "      <td>0.159837</td>\n",
              "      <td>...</td>\n",
              "      <td>1.461499</td>\n",
              "      <td>3.954171</td>\n",
              "      <td>0.309054</td>\n",
              "      <td>0.538184</td>\n",
              "      <td>-7.157865</td>\n",
              "      <td>-4.532216</td>\n",
              "      <td>-0.081800</td>\n",
              "      <td>-9.325362</td>\n",
              "      <td>0.574386</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.355643</td>\n",
              "      <td>2.218601</td>\n",
              "      <td>-1.603269</td>\n",
              "      <td>0.873394</td>\n",
              "      <td>0.401483</td>\n",
              "      <td>0.717264</td>\n",
              "      <td>-0.859399</td>\n",
              "      <td>-1.042190</td>\n",
              "      <td>-2.175965</td>\n",
              "      <td>0.980231</td>\n",
              "      <td>...</td>\n",
              "      <td>0.544434</td>\n",
              "      <td>-2.466258</td>\n",
              "      <td>-0.470256</td>\n",
              "      <td>0.073018</td>\n",
              "      <td>-2.203531</td>\n",
              "      <td>-2.299263</td>\n",
              "      <td>-1.742761</td>\n",
              "      <td>-0.271579</td>\n",
              "      <td>-0.359285</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.596198</td>\n",
              "      <td>-0.857427</td>\n",
              "      <td>1.772434</td>\n",
              "      <td>-0.639361</td>\n",
              "      <td>1.419409</td>\n",
              "      <td>-0.438525</td>\n",
              "      <td>0.281949</td>\n",
              "      <td>2.345145</td>\n",
              "      <td>1.006230</td>\n",
              "      <td>0.389135</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.025051</td>\n",
              "      <td>-2.422975</td>\n",
              "      <td>1.579807</td>\n",
              "      <td>-0.300713</td>\n",
              "      <td>4.267120</td>\n",
              "      <td>2.893775</td>\n",
              "      <td>1.236697</td>\n",
              "      <td>6.034785</td>\n",
              "      <td>-0.045711</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.840049</td>\n",
              "      <td>-2.489600</td>\n",
              "      <td>-0.844902</td>\n",
              "      <td>-1.594362</td>\n",
              "      <td>-4.688517</td>\n",
              "      <td>0.459637</td>\n",
              "      <td>0.913607</td>\n",
              "      <td>-1.143505</td>\n",
              "      <td>1.263937</td>\n",
              "      <td>-2.040928</td>\n",
              "      <td>...</td>\n",
              "      <td>4.176424</td>\n",
              "      <td>1.341742</td>\n",
              "      <td>0.133565</td>\n",
              "      <td>1.743819</td>\n",
              "      <td>1.531188</td>\n",
              "      <td>2.269808</td>\n",
              "      <td>0.053489</td>\n",
              "      <td>-3.151109</td>\n",
              "      <td>1.603702</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.952534</td>\n",
              "      <td>0.238036</td>\n",
              "      <td>0.331327</td>\n",
              "      <td>0.120452</td>\n",
              "      <td>3.539113</td>\n",
              "      <td>-0.556466</td>\n",
              "      <td>0.517210</td>\n",
              "      <td>2.324479</td>\n",
              "      <td>-0.123064</td>\n",
              "      <td>-2.143993</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.233344</td>\n",
              "      <td>-1.424993</td>\n",
              "      <td>0.443893</td>\n",
              "      <td>-2.239507</td>\n",
              "      <td>1.650853</td>\n",
              "      <td>2.296884</td>\n",
              "      <td>0.438294</td>\n",
              "      <td>1.705011</td>\n",
              "      <td>-1.504149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-3.434088</td>\n",
              "      <td>-1.020016</td>\n",
              "      <td>-0.726931</td>\n",
              "      <td>-1.787934</td>\n",
              "      <td>-3.247447</td>\n",
              "      <td>1.439954</td>\n",
              "      <td>1.075627</td>\n",
              "      <td>-2.812310</td>\n",
              "      <td>2.527895</td>\n",
              "      <td>-6.569889</td>\n",
              "      <td>...</td>\n",
              "      <td>2.058341</td>\n",
              "      <td>-2.655348</td>\n",
              "      <td>0.566760</td>\n",
              "      <td>3.414485</td>\n",
              "      <td>5.391528</td>\n",
              "      <td>0.744789</td>\n",
              "      <td>-3.919345</td>\n",
              "      <td>-5.365949</td>\n",
              "      <td>0.725590</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-0.015335</td>\n",
              "      <td>1.883507</td>\n",
              "      <td>3.221682</td>\n",
              "      <td>2.878762</td>\n",
              "      <td>-3.854459</td>\n",
              "      <td>-1.862864</td>\n",
              "      <td>-0.534772</td>\n",
              "      <td>-6.446245</td>\n",
              "      <td>0.976906</td>\n",
              "      <td>0.268957</td>\n",
              "      <td>...</td>\n",
              "      <td>0.306705</td>\n",
              "      <td>4.747956</td>\n",
              "      <td>-0.484956</td>\n",
              "      <td>7.601766</td>\n",
              "      <td>1.039739</td>\n",
              "      <td>-0.107586</td>\n",
              "      <td>-0.789566</td>\n",
              "      <td>0.282480</td>\n",
              "      <td>0.825853</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.285071</td>\n",
              "      <td>1.618508</td>\n",
              "      <td>-1.700678</td>\n",
              "      <td>1.051307</td>\n",
              "      <td>-2.025566</td>\n",
              "      <td>-0.375928</td>\n",
              "      <td>0.261185</td>\n",
              "      <td>1.514845</td>\n",
              "      <td>-2.452698</td>\n",
              "      <td>0.811538</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.600277</td>\n",
              "      <td>3.054941</td>\n",
              "      <td>0.791745</td>\n",
              "      <td>0.982096</td>\n",
              "      <td>-2.942005</td>\n",
              "      <td>-4.929617</td>\n",
              "      <td>1.660500</td>\n",
              "      <td>-2.192116</td>\n",
              "      <td>0.906871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-1.276148</td>\n",
              "      <td>0.988126</td>\n",
              "      <td>-0.716932</td>\n",
              "      <td>-1.622595</td>\n",
              "      <td>4.793812</td>\n",
              "      <td>0.554143</td>\n",
              "      <td>-0.614424</td>\n",
              "      <td>0.339260</td>\n",
              "      <td>2.159058</td>\n",
              "      <td>0.034622</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.054176</td>\n",
              "      <td>-0.714592</td>\n",
              "      <td>0.096377</td>\n",
              "      <td>-4.757388</td>\n",
              "      <td>0.702176</td>\n",
              "      <td>2.109922</td>\n",
              "      <td>1.396287</td>\n",
              "      <td>3.412685</td>\n",
              "      <td>0.726871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-201af9ae-610a-482d-861b-e0bfd48e71ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-201af9ae-610a-482d-861b-e0bfd48e71ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-201af9ae-610a-482d-861b-e0bfd48e71ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47888ea4-3f53-4ad5-a500-84f66a6b8a32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47888ea4-3f53-4ad5-a500-84f66a6b8a32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47888ea4-3f53-4ad5-a500-84f66a6b8a32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7d80282c-13ba-4885-b6fb-a2d8f59f92e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d80282c-13ba-4885-b6fb-a2d8f59f92e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " * Uses make_classification to create a synthetic dataset, making the example self-contained."
      ],
      "metadata": {
        "id": "hDjhdDfCtcYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Hold-out Method (default training)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_GIc-8ZtnUt9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(\"Hold-out - Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JP6EyIjnY7Z",
        "outputId": "0419d8a1-3322-4894-c321-a27f377be34a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hold-out - Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84       160\n",
            "           1       0.80      0.87      0.83       140\n",
            "\n",
            "    accuracy                           0.84       300\n",
            "   macro avg       0.84      0.84      0.84       300\n",
            "weighted avg       0.84      0.84      0.84       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "print(\"\\nHold-out - Decision Tree:\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RGYTMhcnsSd",
        "outputId": "905cfd20-5a4d-4fa4-f18c-fe32b3467542"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hold-out - Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81       160\n",
            "           1       0.76      0.89      0.82       140\n",
            "\n",
            "    accuracy                           0.82       300\n",
            "   macro avg       0.82      0.82      0.82       300\n",
            "weighted avg       0.83      0.82      0.82       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The results are almost similar with normal training and testing let's use cross-validation."
      ],
      "metadata": {
        "id": "E-kPb2rst2p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. K-Fold Cross-Validation (k=5)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "lr_scores_kf = cross_val_score(lr, X, y, cv=kf, scoring='accuracy')\n",
        "dt_scores_kf = cross_val_score(dt, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(\"\\nK-Fold Cross-Validation (k=5):\")\n",
        "print(f\"Logistic Regression: Mean Accuracy = {lr_scores_kf.mean():.4f}, Std Dev = {lr_scores_kf.std():.4f}\")\n",
        "print(f\"Decision Tree: Mean Accuracy = {dt_scores_kf.mean():.4f}, Std Dev = {dt_scores_kf.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8btCq2in8Ok",
        "outputId": "87580acb-1a09-4a1c-ca43-a8b2318c5909"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K-Fold Cross-Validation (k=5):\n",
            "Logistic Regression: Mean Accuracy = 0.8360, Std Dev = 0.0380\n",
            "Decision Tree: Mean Accuracy = 0.8450, Std Dev = 0.0239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. K-Fold with different k (k=10)\n",
        "kf_10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "lr_scores_kf_10 = cross_val_score(lr, X, y, cv=kf_10, scoring='accuracy')\n",
        "dt_scores_kf_10 = cross_val_score(dt, X, y, cv=kf_10, scoring='accuracy')\n",
        "\n",
        "print(\"\\nK-Fold Cross-Validation (k=10):\")\n",
        "print(f\"Logistic Regression: Mean Accuracy = {lr_scores_kf_10.mean():.4f}, Std Dev = {lr_scores_kf_10.std():.4f}\")\n",
        "print(f\"Decision Tree: Mean Accuracy = {dt_scores_kf_10.mean():.4f}, Std Dev = {dt_scores_kf_10.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV16npe7pSpU",
        "outputId": "8f29ab2a-3830-4110-d9ba-fcb37cfc9f86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K-Fold Cross-Validation (k=10):\n",
            "Logistic Regression: Mean Accuracy = 0.8370, Std Dev = 0.0390\n",
            "Decision Tree: Mean Accuracy = 0.8370, Std Dev = 0.0361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* with k=5 folds decision tree get better mean accuracy and less standard deviation(lower is better) , but still not much\n",
        "though .let's try  stratified k-fold."
      ],
      "metadata": {
        "id": "NAFdoHmEuW-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Stratified K-Fold Cross-Validation (k=5)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "lr_scores_skf = cross_val_score(lr, X, y, cv=skf, scoring='accuracy')\n",
        "dt_scores_skf = cross_val_score(dt, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"\\nStratified K-Fold Cross-Validation (k=5):\")\n",
        "print(f\"Logistic Regression: Mean Accuracy = {lr_scores_skf.mean():.4f}, Std Dev = {lr_scores_skf.std():.4f}\")\n",
        "print(f\"Decision Tree: Mean Accuracy = {dt_scores_skf.mean():.4f}, Std Dev = {dt_scores_skf.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8e6i1KXobsy",
        "outputId": "ac8f760a-59c1-4c2c-fb18-2c4e1dd0eae3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stratified K-Fold Cross-Validation (k=5):\n",
            "Logistic Regression: Mean Accuracy = 0.8410, Std Dev = 0.0275\n",
            "Decision Tree: Mean Accuracy = 0.8320, Std Dev = 0.0157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Stratified K-Fold Cross-Validation (k=5)\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "lr_scores_skf = cross_val_score(lr, X, y, cv=skf, scoring='accuracy')\n",
        "dt_scores_skf = cross_val_score(dt, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"\\nStratified K-Fold Cross-Validation (k=10):\")\n",
        "print(f\"Logistic Regression: Mean Accuracy = {lr_scores_skf.mean():.4f}, Std Dev = {lr_scores_skf.std():.4f}\")\n",
        "print(f\"Decision Tree: Mean Accuracy = {dt_scores_skf.mean():.4f}, Std Dev = {dt_scores_skf.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5VHEBFypD0l",
        "outputId": "7197e9a6-777d-4132-901c-553167315796"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stratified K-Fold Cross-Validation (k=10):\n",
            "Logistic Regression: Mean Accuracy = 0.8390, Std Dev = 0.0359\n",
            "Decision Tree: Mean Accuracy = 0.8240, Std Dev = 0.0585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* with stratified k-fold(k=10), logistic regression got a bit good results then decision tree. let's try LOOCV."
      ],
      "metadata": {
        "id": "e4mg2HGGvPaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Leave-One-Out Cross-Validation (LOOCV)\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "lr_scores_loo = cross_val_score(lr, X, y, cv=loo, scoring='accuracy')\n",
        "dt_scores_loo = cross_val_score(dt, X, y, cv=loo, scoring='accuracy')\n",
        "\n",
        "print(\"\\nLeave-One-Out Cross-Validation:\")\n",
        "print(f\"Logistic Regression: Mean Accuracy = {lr_scores_loo.mean():.4f}\") #No std as each test set is only 1 sample\n",
        "print(f\"Decision Tree: Mean Accuracy = {dt_scores_loo.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98FnMc7NpfHX",
        "outputId": "bb511da4-e0a8-48a0-959a-fee6a769fdf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Leave-One-Out Cross-Validation:\n",
            "Logistic Regression: Mean Accuracy = 0.8380\n",
            "Decision Tree: Mean Accuracy = 0.8300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* no change at all with LOOCV(LeaveOneOut cross-validation). let's do Nested cross-validation with hyperparameter tuning."
      ],
      "metadata": {
        "id": "Zwz51bFovpj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Nested Cross-Validation with Hyperparameter Tuning for Logistic Regression\n",
        "param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['elasticnet'], 'solver':['saga'], 'l1_ratio': [0.1, 0.5, 0.9]} # Example grid for Logistic Regression\n",
        "\n",
        "nested_cv_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid_lr, cv=5, scoring='accuracy',n_jobs=-1)  # Inner CV is 5-fold, set n_jobs for parallel processing\n",
        "nested_cv_lr.fit(X, y)\n",
        "\n",
        "print(\"\\nNested Cross-Validation with Hyperparameter Tuning (Logistic Regression):\")\n",
        "print(f\"Best Hyperparameters: {nested_cv_lr.best_params_}\")\n",
        "print(f\"Best Score: {nested_cv_lr.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6h6JQlrEhj",
        "outputId": "bd3c0033-6483-4ae2-83e6-3686472636f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nested Cross-Validation with Hyperparameter Tuning (Logistic Regression):\n",
            "Best Hyperparameters: {'C': 0.1, 'l1_ratio': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
            "Best Score: 0.8460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Nested Cross-Validation with Hyperparameter Tuning\n",
        "param_grid_dt = {'max_depth': [None, 5, 10, 15], 'min_samples_split': [2, 5, 10]} # Example grid\n",
        "\n",
        "nested_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, scoring='accuracy') # Inner CV is 5-fold\n",
        "nested_cv.fit(X, y)\n",
        "\n",
        "print(\"\\nNested Cross-Validation with Hyperparameter Tuning (Decision Tree):\")\n",
        "print(f\"Best Hyperparameters: {nested_cv.best_params_}\")\n",
        "print(f\"Best Score: {nested_cv.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv6hFf81po6t",
        "outputId": "1c546533-e3a7-4cac-92de-dd763865a0a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nested Cross-Validation with Hyperparameter Tuning (Decision Tree):\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 5}\n",
            "Best Score: 0.8360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FI7oeuGpv-8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here i use elasticnet (regularization) for LogisticRegression to find hyperparameters using GridSearchCV and for decision tree depth and min samples as a hyperparameters. the results are not much different as data is less and for basic implementation purspose i used simple synthetic data in realtime data we need to do feature engineering before training  then we can apply cross-validation to find best model for our data. of couse it need some experimentation with parameters and enough knowledge to tune the model. you  can find basic implemenations of evalution metrics for classfication , regression and clustering in my repo, feel free to check it out."
      ],
      "metadata": {
        "id": "oCHbdu70wUpM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}